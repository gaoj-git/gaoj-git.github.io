---
layout: mypost
title: kafka大数据量消费推送数据到第三方平台消息积压的解决方案
categories: [kafka]
extMath: true
---

## 现象
有1000台设备会定期30秒发送心跳数据到平台上，平台这边接收到后会发到kafka里面，然后去消费，对数据进行一些处理，然后这个时候有个第三方需要我们把这些数据实时的推送给他们，开始的实现方案是在消费的时候发送http请求，将数据推送给他们，不过会出现消息积压导致很多数据推送比较晚，没有实时性。

----------
## 解决
后来查阅了下相关资料，得知kafka的消费是单线程的。
kafka设计原理
  首先，kafka Java consumer是单线程的设计。准确来说是双线程，从kafka 0.10.1.0版本开始kafkaConsumer变成了用户主线程和心跳线程的双线程设计。
  所谓用户主线程，就是你启动Consumer应用程序的main方法的那个线程。而心跳线程（Heartbeat Thread）只负责定期发送心跳给对应的Boroker,以标识消费者应用的存活性。引入心跳线程的目的还有一个：解耦真实的消息处理逻辑与消费者组成员存活性管理。
  尽管多了一个心跳线程，但是实际的消息处理还是由主线程完成。所以我们还是可以认为KafkaConsumer是单线程设计的。

既然如此，那么可以在消费逻辑里面使用多线程来进行处理，多线程代码块
``` java
//线程池创建
//核心线程默认5个，最大线程100个，空闲线程5秒后回收，没有空余线程来处理任务的，放到ArrayBlockingQueue队列里面，长度为1000的有界队列。
public static ExecutorService pool = new ThreadPoolExecutor(5,100, 5000,
            TimeUnit.MILLISECONDS, new ArrayBlockingQueue<Runnable>(1000), Executors.defaultThreadFactory(),
            new ThreadPoolExecutor.AbortPolicy());


//kafka消费逻辑，伪代码如下
@KafkaListener(topics = "${spring.kafka.kafkaHLHTHeartPushTopic}", groupId = "${spring.kafka.kafkaHLHTPushGroup}")
public void hlhtPushHeartMsgConsume(ConsumerRecord<?, ?> record, Acknowledgment ack, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic){
	pool.submit(new Runnable() {
		@Override
		public void run() {
			//消费业务逻辑处理
		}	
	});
}
```
然后发布到测试环境，模拟了下，消费正常，发布上线，观察了下日志，消费都是正常，至此问题解决。

==PS:以上的方式因为是多线程执行，所有是不能保证顺序消费的，如果需要按顺序消费可能需要考虑某个业务场景的消息都指定消息发送端发送到某个分区内，然后消费端也指定从这个分区中读取进行消费，关于分区投递可以取模获取分区编号，这个需要结合具体的业务场景。 #F44336==